#!/usr/bin/env python3
"""
Jira ì´ìŠˆ ê¸°ë°˜ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

Jiraì—ì„œ íŠ¹ì • ì´ìŠˆë¥¼ ê°€ì ¸ì™€ì„œ issue_processor.process_issue()ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
ì›¹í›… ì—†ì´ ë¡œì»¬ì—ì„œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python test/test_issue_from_jira.py --issue-key GEN-11075
    python test/test_issue_from_jira.py --issue-url https://midasitdev.atlassian.net/browse/GEN-11075
"""

import os
import sys
import json
import logging
import requests
from datetime import datetime

# í”„ë¡œì íŠ¸ ê²½ë¡œë¥¼ Python pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from dotenv import load_dotenv
from app.bitbucket_api import BitbucketAPI
from app.llm_handler import LLMHandler
from app.issue_processor import IssueProcessor

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('test_issue_from_jira.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


def fetch_jira_issue(issue_key: str, jira_url: str = None, jira_email: str = None, jira_api_token: str = None) -> dict:
    """
    Jira APIë¥¼ í†µí•´ ì´ìŠˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°

    Args:
        issue_key: Jira ì´ìŠˆ í‚¤ (ì˜ˆ: GEN-11075)
        jira_url: Jira ì¸ìŠ¤í„´ìŠ¤ URL (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ JIRA_URL)
        jira_email: Jira ì‚¬ìš©ì ì´ë©”ì¼ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ JIRA_EMAIL)
        jira_api_token: Jira API í† í° (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ JIRA_API_TOKEN)

    Returns:
        Jira ì´ìŠˆ ì •ë³´ (webhook payloadì˜ 'issue' ë¶€ë¶„ê³¼ ë™ì¼í•œ í˜•ì‹)
    """
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ Jira ì„¤ì • ë¡œë“œ
    if not jira_url:
        jira_url = os.getenv('JIRA_URL', 'https://midasitdev.atlassian.net')
    if not jira_email:
        jira_email = os.getenv('JIRA_EMAIL')
    if not jira_api_token:
        jira_api_token = os.getenv('JIRA_API_TOKEN')

    if not jira_email or not jira_api_token:
        raise ValueError(
            "Jira ì¸ì¦ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ JIRA_EMAILê³¼ JIRA_API_TOKENì„ ì„¤ì •í•˜ê±°ë‚˜ "
            ".env íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”.\n\n"
            "ì˜ˆì‹œ:\n"
            "JIRA_URL=https://midasitdev.atlassian.net\n"
            "JIRA_EMAIL=your-email@example.com\n"
            "JIRA_API_TOKEN=your-jira-api-token\n"
        )

    # Jira REST API ì—”ë“œí¬ì¸íŠ¸
    api_url = f"{jira_url}/rest/api/3/issue/{issue_key}"

    logger.info(f"Jira API í˜¸ì¶œ: {api_url}")

    try:
        response = requests.get(
            api_url,
            auth=(jira_email, jira_api_token),
            headers={
                'Accept': 'application/json',
                'Content-Type': 'application/json'
            }
        )

        response.raise_for_status()
        issue_data = response.json()

        logger.info(f"âœ… Jira ì´ìŠˆ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ: {issue_key}")
        logger.info(f"  - ìš”ì•½: {issue_data.get('fields', {}).get('summary', 'N/A')}")
        logger.info(f"  - ìƒíƒœ: {issue_data.get('fields', {}).get('status', {}).get('name', 'N/A')}")
        logger.info(f"  - ì´ìŠˆ íƒ€ì…: {issue_data.get('fields', {}).get('issuetype', {}).get('name', 'N/A')}")

        return issue_data

    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 401:
            logger.error("Jira ì¸ì¦ ì‹¤íŒ¨. JIRA_EMAILê³¼ JIRA_API_TOKENì„ í™•ì¸í•˜ì„¸ìš”.")
        elif e.response.status_code == 404:
            logger.error(f"ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {issue_key}")
        else:
            logger.error(f"Jira API ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
        raise
    except Exception as e:
        logger.error(f"Jira ì´ìŠˆ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
        raise


def create_webhook_payload(issue: dict) -> dict:
    """
    Jira ì´ìŠˆ ì •ë³´ë¥¼ ì›¹í›… í˜ì´ë¡œë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

    Args:
        issue: Jira APIì—ì„œ ê°€ì ¸ì˜¨ ì´ìŠˆ ì •ë³´

    Returns:
        ì›¹í›… í˜ì´ë¡œë“œ í˜•ì‹ì˜ ë”•ì…”ë„ˆë¦¬
    """
    payload = {
        "timestamp": int(datetime.now().timestamp() * 1000),
        "webhookEvent": "jira:issue_created",
        "issue_event_type_name": "issue_created",
        "issue": issue
    }

    return payload


def test_issue_processor(issue_key: str, save_payload: bool = True, output_dir: str = "test_output"):
    """
    Jira ì´ìŠˆë¥¼ ê°€ì ¸ì™€ì„œ issue_processor.process_issue() í…ŒìŠ¤íŠ¸

    Args:
        issue_key: Jira ì´ìŠˆ í‚¤ (ì˜ˆ: GEN-11075)
        save_payload: í˜ì´ë¡œë“œë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€
        output_dir: ì¶œë ¥ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    logger.info("="*80)
    logger.info(f"Jira ì´ìŠˆ í”„ë¡œì„¸ì„œ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œì‘: {issue_key}")
    logger.info("="*80)

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    try:
        # 1. Jiraì—ì„œ ì´ìŠˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        logger.info("\n[Step 1] Jira APIì—ì„œ ì´ìŠˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°...")
        issue = fetch_jira_issue(issue_key)

        # ì›¹í›… í˜ì´ë¡œë“œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        webhook_payload = create_webhook_payload(issue)

        # í˜ì´ë¡œë“œ ì €ì¥ (ì„ íƒì‚¬í•­)
        if save_payload:
            payload_file = os.path.join(output_dir, f"{timestamp}_{issue_key}_payload.json")
            with open(payload_file, 'w', encoding='utf-8') as f:
                json.dump(webhook_payload, f, indent=2, ensure_ascii=False)
            logger.info(f"âœ… í˜ì´ë¡œë“œ ì €ì¥: {payload_file}")

        # 2. Bitbucket API ì´ˆê¸°í™”
        logger.info("\n[Step 2] Bitbucket API ì´ˆê¸°í™”...")
        bitbucket_url = os.getenv('BITBUCKET_URL', 'https://api.bitbucket.org')
        bitbucket_username = os.getenv('BITBUCKET_USERNAME')
        bitbucket_access_token = os.getenv('BITBUCKET_ACCESS_TOKEN')
        bitbucket_repository = os.getenv('BITBUCKET_REPOSITORY', 'genw_new')
        bitbucket_workspace = os.getenv('BITBUCKET_WORKSPACE', 'mit_dev')

        if not all([bitbucket_access_token, bitbucket_repository, bitbucket_workspace]):
            raise ValueError(
                "Bitbucket ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”:\n"
                "BITBUCKET_ACCESS_TOKEN, BITBUCKET_REPOSITORY, BITBUCKET_WORKSPACE"
            )

        bitbucket_api = BitbucketAPI(
            url=bitbucket_url,
            username=bitbucket_username,
            access_token=bitbucket_access_token,
            workspace=bitbucket_workspace,
            repository=bitbucket_repository
        )

        logger.info(f"âœ… Bitbucket ì—°ê²°: {bitbucket_workspace}/{bitbucket_repository}")

        # 3. LLM í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        logger.info("\n[Step 3] LLM í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”...")
        llm_handler = LLMHandler()

        if llm_handler.client:
            logger.info(f"âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {llm_handler.model})")
        else:
            logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. LLM ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

        # 4. IssueProcessor ì´ˆê¸°í™”
        logger.info("\n[Step 4] IssueProcessor ì´ˆê¸°í™”...")
        issue_processor = IssueProcessor(bitbucket_api, llm_handler)
        logger.info("âœ… IssueProcessor ì´ˆê¸°í™” ì™„ë£Œ")

        # 5. ì´ìŠˆ ì²˜ë¦¬ ì‹¤í–‰ (main.pyì˜ webhook_handlerì™€ ë™ì¼í•œ íë¦„)
        logger.info("\n[Step 5] ì´ìŠˆ ì²˜ë¦¬ ì‹œì‘...")
        logger.info("="*80)

        result = issue_processor.process_issue(issue)

        logger.info("="*80)
        logger.info("\n[Step 6] ì²˜ë¦¬ ê²°ê³¼:")
        logger.info(f"  - ìƒíƒœ: {result.get('status')}")
        logger.info(f"  - ì´ìŠˆ í‚¤: {result.get('issue_key')}")
        logger.info(f"  - ë¸Œëœì¹˜: {result.get('branch_name')}")
        logger.info(f"  - PR URL: {result.get('pr_url', 'N/A')}")
        logger.info(f"  - ìˆ˜ì •ëœ íŒŒì¼: {len(result.get('modified_files', []))}ê°œ")

        if result.get('modified_files'):
            logger.info("\n  ìˆ˜ì •ëœ íŒŒì¼ ëª©ë¡:")
            for file_info in result['modified_files']:
                encoding_info = f", ì¸ì½”ë”©: {file_info.get('encoding', 'N/A')}" if 'encoding' in file_info else ""
                logger.info(f"    - {file_info['path']} ({file_info['action']}, {file_info.get('diff_count', 0)}ê°œ ë³€ê²½{encoding_info})")

        if result.get('errors'):
            logger.warning(f"\n  âš ï¸ ì˜¤ë¥˜ {len(result['errors'])}ê°œ:")
            for error in result['errors']:
                logger.warning(f"    - {error}")

        # ê²°ê³¼ ì €ì¥
        result_file = os.path.join(output_dir, f"{timestamp}_{issue_key}_result.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        logger.info(f"\nâœ… ì²˜ë¦¬ ê²°ê³¼ ì €ì¥: {result_file}")

        # ìˆ˜ì •ëœ íŒŒì¼ë“¤ ì €ì¥ (modified_contentì™€ diff) - ì¸ì½”ë”© ì •ë³´ í¬í•¨
        if result.get('modified_files'):
            logger.info(f"\nğŸ“ ìˆ˜ì •ëœ íŒŒì¼ ì €ì¥ ì¤‘...")
            for file_info in result['modified_files']:
                file_path = file_info.get('path', '')
                modified_content = file_info.get('modified_content', '')
                diff = file_info.get('diff', '')
                encoding = file_info.get('encoding', 'utf-8')

                if file_path:
                    # íŒŒì¼ëª…ì—ì„œ ê²½ë¡œ êµ¬ë¶„ìë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                    safe_filename = file_path.replace("/", "_").replace("\\", "_")

                    # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
                    file_ext = os.path.splitext(file_path)[1] or '.txt'

                    # ìˆ˜ì •ëœ íŒŒì¼ ë‚´ìš© ì €ì¥ (ì›ë³¸ ì¸ì½”ë”©ìœ¼ë¡œ ì €ì¥ ì‹œë„)
                    if modified_content:
                        modified_file = os.path.join(output_dir, f"{timestamp}_{issue_key}_{safe_filename}_modified{file_ext}")
                        try:
                            # ì›ë³¸ ì¸ì½”ë”©ìœ¼ë¡œ ì €ì¥
                            with open(modified_file, 'w', encoding=encoding) as f:
                                f.write(modified_content)
                            logger.info(f"  âœ… ìˆ˜ì •ëœ íŒŒì¼ ì €ì¥: {modified_file} (ì¸ì½”ë”©: {encoding})")
                        except (UnicodeEncodeError, LookupError):
                            # ì¸ì½”ë”© ì‹¤íŒ¨ ì‹œ UTF-8ë¡œ í´ë°±
                            with open(modified_file, 'w', encoding='utf-8') as f:
                                f.write(modified_content)
                            logger.warning(f"  âš ï¸ {encoding} ì¸ì½”ë”© ì‹¤íŒ¨, UTF-8ë¡œ ì €ì¥: {modified_file}")

                    # Diff ì €ì¥
                    if diff:
                        diff_file = os.path.join(output_dir, f"{timestamp}_{issue_key}_{safe_filename}.diff")
                        with open(diff_file, 'w', encoding='utf-8') as f:
                            f.write(diff)
                        logger.info(f"  âœ… Diff íŒŒì¼ ì €ì¥: {diff_file}")

                        # Diff ë¼ì¸ ìˆ˜ ê³„ì‚° (ì‹¤ì œ ë³€ê²½ í™•ì¸)
                        added_lines = sum(1 for line in diff.split('\n') if line.startswith('+') and not line.startswith('+++'))
                        removed_lines = sum(1 for line in diff.split('\n') if line.startswith('-') and not line.startswith('---'))
                        logger.info(f"     Diff í†µê³„: +{added_lines}ì¤„, -{removed_lines}ì¤„")

        # ìµœì¢… ìš”ì•½
        logger.info("\n" + "="*80)
        if result.get('status') == 'completed':
            logger.info("âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            logger.info(f"   ë¸Œëœì¹˜: {result.get('branch_name')}")
            logger.info(f"   PR: {result.get('pr_url')}")

            # ì¸ì½”ë”© ìœ ì§€ í™•ì¸
            logger.info("\nğŸ“Š ì¸ì½”ë”© ìœ ì§€ ê²€ì¦:")
            for file_info in result.get('modified_files', []):
                encoding = file_info.get('encoding', 'N/A')
                logger.info(f"   âœ… {file_info['path']}: {encoding} ìœ ì§€")

        elif result.get('status') == 'failed':
            logger.error("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            logger.error(f"   ì˜¤ë¥˜: {result.get('errors')}")
        else:
            logger.warning(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ìƒíƒœ: {result.get('status')})")

        # ì €ì¥ëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
        logger.info(f"\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
        logger.info(f"  - JSON ê²°ê³¼: {result_file}")
        if result.get('modified_files'):
            logger.info(f"  - ìˆ˜ì •ëœ íŒŒì¼ë“¤: {output_dir}/{timestamp}_{issue_key}_*_modified.*")
            logger.info(f"  - Diff íŒŒì¼ë“¤: {output_dir}/{timestamp}_{issue_key}_*.diff")

        # Bitbucket PR í™•ì¸ ê°€ì´ë“œ
        if result.get('pr_url'):
            logger.info(f"\nğŸ” ì¸ì½”ë”© ìœ ì§€ ê²€ì¦ ë°©ë²•:")
            logger.info(f"  1. Bitbucket PR í™•ì¸: {result.get('pr_url')}")
            logger.info(f"  2. 'Diff' íƒ­ì—ì„œ ë³€ê²½ ë¼ì¸ ìˆ˜ í™•ì¸")
            logger.info(f"  3. ì „ì²´ íŒŒì¼ì´ ë³€ê²½ëœ ê²ƒì´ ì•„ë‹ˆë¼ ì‹¤ì œ ìˆ˜ì •ëœ ë¼ì¸ë§Œ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸")
            logger.info(f"  4. ë¡œì»¬ì—ì„œ diff í™•ì¸:")
            logger.info(f"     git diff master..{result.get('branch_name')} | grep -E '^[+-]' | wc -l")

        logger.info("="*80)

        return result

    except Exception as e:
        logger.error(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}", exc_info=True)
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    # ============================================================
    # ğŸ”§ ë””ë²„ê¹…ìš© ì„¤ì •: ì´ìŠˆ í‚¤ë¥¼ ì—¬ê¸°ì„œ ê³ ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
    # ============================================================
    DEBUG_MODE = True  # Trueë¡œ ì„¤ì •í•˜ë©´ ì•„ë˜ ê³ ì •ê°’ ì‚¬ìš©
    DEBUG_ISSUE_KEY = "GEN-11075"  # ë””ë²„ê¹…í•  ì´ìŠˆ í‚¤
    DEBUG_SAVE_PAYLOAD = True  # í˜ì´ë¡œë“œ ì €ì¥ ì—¬ë¶€
    DEBUG_OUTPUT_DIR = "test_output"  # ì¶œë ¥ ë””ë ‰í† ë¦¬
    # ============================================================

    if DEBUG_MODE:
        # ë””ë²„ê·¸ ëª¨ë“œ: ê³ ì •ëœ ì´ìŠˆ í‚¤ë¡œ ì‹¤í–‰
        logger.info("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”")
        logger.info(f"   ì´ìŠˆ í‚¤: {DEBUG_ISSUE_KEY}")
        logger.info(f"   ì¶œë ¥ ë””ë ‰í† ë¦¬: {DEBUG_OUTPUT_DIR}")

        try:
            result = test_issue_processor(
                issue_key=DEBUG_ISSUE_KEY,
                save_payload=DEBUG_SAVE_PAYLOAD,
                output_dir=DEBUG_OUTPUT_DIR
            )

            # ì„±ê³µ ì—¬ë¶€ì— ë”°ë¼ ì¢…ë£Œ ì½”ë“œ ë°˜í™˜
            if result.get('status') == 'completed':
                sys.exit(0)
            else:
                sys.exit(1)

        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            sys.exit(1)

    else:
        # ì¼ë°˜ ëª¨ë“œ: ëª…ë ¹ì¤„ ì¸ì ì‚¬ìš©
        parser = argparse.ArgumentParser(
            description='Jira ì´ìŠˆë¥¼ ê°€ì ¸ì™€ì„œ issue_processor.process_issue() í…ŒìŠ¤íŠ¸',
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
ì˜ˆì‹œ:
  # ì´ìŠˆ í‚¤ë¡œ í…ŒìŠ¤íŠ¸
  python test/test_issue_from_jira.py --issue-key GEN-11075

  # URLë¡œ í…ŒìŠ¤íŠ¸
  python test/test_issue_from_jira.py --issue-url https://midasitdev.atlassian.net/browse/GEN-11075

  # í˜ì´ë¡œë“œ ì €ì¥ ì•ˆí•¨
  python test/test_issue_from_jira.py --issue-key GEN-11075 --no-save-payload

í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜:
  JIRA_URL                 - Jira ì¸ìŠ¤í„´ìŠ¤ URL (ê¸°ë³¸ê°’: https://midasitdev.atlassian.net)
  JIRA_EMAIL               - Jira ì‚¬ìš©ì ì´ë©”ì¼
  JIRA_API_TOKEN           - Jira API í† í°
  BITBUCKET_ACCESS_TOKEN   - Bitbucket ì•¡ì„¸ìŠ¤ í† í°
  BITBUCKET_WORKSPACE      - Bitbucket ì›Œí¬ìŠ¤í˜ì´ìŠ¤
  BITBUCKET_REPOSITORY     - Bitbucket ì €ì¥ì†Œ
  OPENAI_API_KEY           - OpenAI API í‚¤ (ì„ íƒ)
            """
        )

        parser.add_argument('--issue-key', help='Jira ì´ìŠˆ í‚¤ (ì˜ˆ: GEN-11075)')
        parser.add_argument('--issue-url', help='Jira ì´ìŠˆ URL')
        parser.add_argument('--no-save-payload', action='store_true', help='í˜ì´ë¡œë“œë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ')
        parser.add_argument('--output-dir', default='test_output', help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: test_output)')

        args = parser.parse_args()

        # ì´ìŠˆ í‚¤ ë˜ëŠ” URLì—ì„œ ì¶”ì¶œ
        issue_key = args.issue_key

        if args.issue_url and not issue_key:
            # URLì—ì„œ ì´ìŠˆ í‚¤ ì¶”ì¶œ (ì˜ˆ: https://midasitdev.atlassian.net/browse/GEN-11075 -> GEN-11075)
            import re
            match = re.search(r'/browse/([A-Z]+-\d+)', args.issue_url)
            if match:
                issue_key = match.group(1)
            else:
                logger.error("URLì—ì„œ ì´ìŠˆ í‚¤ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                sys.exit(1)

        if not issue_key:
            parser.print_help()
            print("\nâŒ ì˜¤ë¥˜: --issue-key ë˜ëŠ” --issue-url ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
            sys.exit(1)

        try:
            result = test_issue_processor(
                issue_key=issue_key,
                save_payload=not args.no_save_payload,
                output_dir=args.output_dir
            )

            # ì„±ê³µ ì—¬ë¶€ì— ë”°ë¼ ì¢…ë£Œ ì½”ë“œ ë°˜í™˜
            if result.get('status') == 'completed':
                sys.exit(0)
            else:
                sys.exit(1)

        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            sys.exit(1)


if __name__ == "__main__":
    main()
